{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG: parse image path https://en.wikipedia.org/static/images/icons/wikipedia.png\n",
      "Saved successfuly on path: ./wiki.png\n",
      "LOG: parse image path https://www.google.com/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\n",
      "Saved successfuly on path: ./google.png\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class WebsiteImageParser:\n",
    "    def __init__(\n",
    "        self,\n",
    "        url,\n",
    "        save_path=\"test.png\",\n",
    "    ) -> None:\n",
    "        self.url = url\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        template method - он определяет общую структуру всего алгоритма\n",
    "        \"\"\"\n",
    "        html = self.get_html(url=self.url)\n",
    "        soup = self.get_soup(html=html)\n",
    "        img_path = self.extract_img(soup=soup)\n",
    "        print(f\"LOG: parse image path {img_path}\")\n",
    "        self.save_image(img_path=img_path)\n",
    "        print(f\"Saved successfuly on path: {self.save_path}\")\n",
    "\n",
    "    def extract_img(self, soup):\n",
    "        raise \"You should write this method\"\n",
    "\n",
    "    def get_html(self, url):\n",
    "        response = requests.get(url=url)\n",
    "        return response.text\n",
    "\n",
    "    def get_soup(self, html):\n",
    "        soup = BeautifulSoup(html)\n",
    "        return soup\n",
    "\n",
    "    def save_image(self, img_path):\n",
    "        r = requests.get(img_path, allow_redirects=True)\n",
    "        with open(self.save_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "\n",
    "class WikiParser(WebsiteImageParser):\n",
    "    def extract_img(self, soup):\n",
    "        image = soup.find(\"img\", class_=\"mw-logo-icon\")\n",
    "        image = image[\"src\"]\n",
    "        image = f\"https://en.wikipedia.org{image}\"\n",
    "        return image\n",
    "\n",
    "\n",
    "class GoogleParser(WebsiteImageParser):\n",
    "    def extract_img(self, soup):\n",
    "        image = soup.find(\"img\")\n",
    "        image = image[\"src\"]\n",
    "        image = f\"https://www.google.com{image}\"\n",
    "        return image\n",
    "\n",
    "\n",
    "wiki_parser = WikiParser(\n",
    "    url=\"https://en.wikipedia.org/wiki/Main_Page\",\n",
    "    save_path=\"./wiki.png\",\n",
    ")\n",
    "wiki_parser.parse()\n",
    "\n",
    "google_parser = GoogleParser(\n",
    "    url=\"https://www.google.com/\",\n",
    "    save_path=\"./google.png\",\n",
    ")\n",
    "\n",
    "google_parser.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class ParserFactory(ABC):\n",
    "    @abstractmethod\n",
    "    def create_parser(self, url, save_path):\n",
    "        pass\n",
    "\n",
    "\n",
    "class WikiParserFactory(ParserFactory):\n",
    "    def create_parser(self, url, save_path):\n",
    "        self.some_logic_1()\n",
    "        return WikiParser(url=url, save_path=save_path)\n",
    "\n",
    "    def some_logic_1(self):\n",
    "        print(\"do some logic 1\")\n",
    "\n",
    "\n",
    "class GoogleParserFactory(ParserFactory):\n",
    "    def create_parser(self, url, save_path):\n",
    "        self.some_logic_2()\n",
    "        return GoogleParser(url=url, save_path=save_path)\n",
    "\n",
    "    def some_logic_2(self):\n",
    "        print(\"do some logic 2\")\n",
    "\n",
    "\n",
    "wiki_factory = WikiParserFactory()\n",
    "google_factory = GoogleParserFactory()\n",
    "\n",
    "google_params = [\n",
    "    [\"https://www.google.com/\", \"./google_1.png\"],\n",
    "    [\"https://www.google.com/\", \"./google_2.png\"],\n",
    "    [\"https://www.google.com/\", \"./google_3.png\"],\n",
    "]\n",
    "\n",
    "parsers: list[GoogleParser] = []\n",
    "\n",
    "for param in google_params:\n",
    "    url, save_path = param\n",
    "    parser = google_factory.create_parser(url=url, save_path=save_path)\n",
    "    parsers.append(parser)\n",
    "\n",
    "for parser in parsers:\n",
    "    parser.parse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def template(\n",
    "    get_html: Callable,\n",
    "    get_soup: Callable,\n",
    "    extract_img: Callable,\n",
    "    save_image: Callable,\n",
    "):\n",
    "    \"\"\"Template method definition\"\"\"\n",
    "\n",
    "    html = get_html()\n",
    "    soup = get_soup(html)\n",
    "    img_path = extract_img(soup)\n",
    "    print(f\"LOG: Extracted image path {img_path}\")\n",
    "    save_image(img_path)\n",
    "    print(\"Image saved successfully!\")\n",
    "\n",
    "\n",
    "def get_html(url: str) -> str:\n",
    "    \"\"\"Get HTML content\"\"\"\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def get_soup(html: str) -> BeautifulSoup:\n",
    "    \"\"\"Parse HTML into Beautiful Soup\"\"\"\n",
    "    return BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "def save_image(img_path: str, filepath: str) -> None:\n",
    "    \"\"\"Save image from URL to file\"\"\"\n",
    "    response = requests.get(img_path)\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "\n",
    "def wiki_strategy(soup: BeautifulSoup) -> str:\n",
    "    \"\"\"Extract image strategy for Wikipedia\"\"\"\n",
    "    img = soup.find(\"img\", class_=\"mw-logo-icon\")\n",
    "    return f\"https://en.wikipedia.org{img['src']}\"\n",
    "\n",
    "\n",
    "def google_strategy(soup: BeautifulSoup) -> str:\n",
    "    \"\"\"Extract image strategy for Google\"\"\"\n",
    "    img = soup.find(\"img\")\n",
    "    return f\"https://www.google.com{img['src']}\"\n",
    "\n",
    "\n",
    "parser = lambda url, filepath: partial(\n",
    "    template,\n",
    "    partial(get_html, url),\n",
    "    get_soup=get_soup,\n",
    "    extract_img=wiki_strategy,\n",
    "    save_image=partial(save_image, filepath=filepath),\n",
    ")\n",
    "\n",
    "wiki_parser = parser(\n",
    "    url=\"https://en.wikipedia.org/wiki/Main_Page\",\n",
    "    filepath=\"wiki_func.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki_factory_logic\n",
      "wiki_factory_logic\n",
      "wiki_factory_logic\n",
      "LOG: Extracted image path https://en.wikipedia.org/static/images/icons/wikipedia.png\n",
      "Image saved successfully!\n",
      "LOG: Extracted image path https://en.wikipedia.org/static/images/icons/wikipedia.png\n",
      "Image saved successfully!\n",
      "LOG: Extracted image path https://en.wikipedia.org/static/images/icons/wikipedia.png\n",
      "Image saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def parser_factory(\n",
    "    factory_logic: Callable[[], None],\n",
    ") -> Callable[[str, str], object]:\n",
    "    def create_parser(*args, **kwargs):\n",
    "        return factory_logic(*args, **kwargs)\n",
    "\n",
    "    return create_parser\n",
    "\n",
    "\n",
    "def wiki_factory_logic(*args, **kwargs):\n",
    "    print(\"wiki_factory_logic\")\n",
    "    print(\"I love wikipedia.\")\n",
    "    return parser(*args, **kwargs)\n",
    "\n",
    "\n",
    "def google_parser_logic(*args, **kwargs):\n",
    "    print(\"google_parser_logic\")\n",
    "    return parser(*args, **kwargs)\n",
    "\n",
    "\n",
    "# Create factory functions\n",
    "wiki_parser_fabric = parser_factory(wiki_factory_logic)\n",
    "google_parser_fabric = parser_factory(google_parser_logic)\n",
    "\n",
    "# Usage:\n",
    "\n",
    "google_params = [\n",
    "    # [\"https://www.google.com/\", \"./google_1_func.png\"],\n",
    "    # [\"https://www.google.com/\", \"./google_2_func.png\"],\n",
    "    # [\"https://www.google.com/\", \"./google_3_func.png\"],\n",
    "    [\"https://en.wikipedia.org/wiki/Main_Page\", \"./wiki_1_func.png\"],\n",
    "    [\"https://en.wikipedia.org/wiki/Main_Page\", \"./wiki_2_func.png\"],\n",
    "    [\"https://en.wikipedia.org/wiki/Main_Page\", \"./wiki_3_func.png\"],\n",
    "]\n",
    "\n",
    "parsers = []\n",
    "\n",
    "for url, save_path in google_params:\n",
    "    # p = google_parser_fabric(url, save_path)\n",
    "    p = wiki_parser_fabric(url, save_path)\n",
    "    parsers.append(p)\n",
    "# parsers\n",
    "for p in parsers:\n",
    "    p()\n",
    "# # Use parsers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
